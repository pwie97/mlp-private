{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lung and Colon Cancer Detection\n",
    "This notebook demonstrates the process of building a machine learning model to detect lung and colon cancer using histopathological images. The dataset contains labeled images of cancerous and non-cancerous (<em>healthy</em>) tissues. There are five classes in this dataset: \n",
    "- Lung benign tissue (<em>healthy</em>)\n",
    "- Lung adenocarcinoma\n",
    "- Lung squamos cell carcinoma\n",
    "- Colon adenocarcinoma\n",
    "- Colong benign tissue (<em>healthy</em>)\n",
    "\n",
    "The goal is to compare different Convolutional Neural Networks (CNNs) to explore the strengths and weaknesses of various architectures and understand which ones perform best for the chosen dataset. Ultimately, the most robust classifier (CNN) will be identified and can accurately identify cancerous lung or colon tissues from the given sample images. For a fair comparison of the different CNNs, it is necessary to set some guidelines / rules:\n",
    "- The dataset has to be properly preprocessed.\n",
    "- The same training parameters are used \n",
    "  - Learning rate\n",
    "  - Batch size\n",
    "  - Number of epochs\n",
    "- The same optimizer is used\n",
    "  - Isolates the effect if the CNN architecture on performance\n",
    "\n",
    "Those rules will ensure that the comparison is consistent, controlled and fair.\n",
    "\n",
    "The dataset used in this notebook is sourced from Kaggle: https://www.kaggle.com/datasets/andrewmvd/lung-and-colon-cancer-histopathological-images/data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Required Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset handling\n",
    "### Import Dataset\n",
    "The dataset containes 25.000 images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes found in lung dataset: ['lung_aca', 'lung_n', 'lung_scc']\n",
      "Classes found in colon dataset: ['colon_aca', 'colon_n']\n",
      "Lung and Colon classes combined: ['colon_aca', 'colon_n', 'lung_aca', 'lung_n', 'lung_scc']\n"
     ]
    }
   ],
   "source": [
    "lung_dataset = '../lung_colon_image_set/lung_image_sets'\n",
    "colon_dataset = '../lung_colon_image_set/colon_image_sets'\n",
    "\n",
    "if not os.path.exists(lung_dataset):\n",
    "    raise FileNotFoundError(f\"Dataset path '{lung_dataset}' does not exist!\")\n",
    "if not os.path.exists(colon_dataset):\n",
    "    raise FileNotFoundError(f\"Dataset path '{colon_dataset}' does not exist!\")\n",
    "\n",
    "lung_classes = sorted(os.listdir(lung_dataset))\n",
    "colon_classes = sorted(os.listdir(colon_dataset))\n",
    "\n",
    "print(f\"Classes found in lung dataset: {lung_classes}\")\n",
    "print(f\"Classes found in colon dataset: {colon_classes}\")\n",
    "\n",
    "lc_classes = sorted(set(lung_classes + colon_classes))\n",
    "print(f\"Lung and Colon classes combined: {lc_classes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Dataset\n",
    "The dataset is split into the following three categories with pre defined percentages:\n",
    "- Training data (<em>80 %</em>)\n",
    "- Validation data (<em>10 %</em>)\n",
    "- Testing data (<em>10 %</em>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 'lung_aca' has 5000 images\n",
      "Class 'lung_n' has 5000 images\n",
      "Class 'lung_scc' has 5000 images\n",
      "Class 'colon_aca' has 5000 images\n",
      "Class 'colon_n' has 5000 images\n",
      "Training dataset has 20000 images\n",
      "Validation dataset has 2500 images\n",
      "Testing dataset has 2500 images\n"
     ]
    }
   ],
   "source": [
    "def prepare_splits(data_directories, split_ratios=(0.8, 0.1, 0.1)):\n",
    "    all_data = {}\n",
    "    for data_directory in data_directories:\n",
    "        for class_name in sorted(os.listdir(data_directory)):\n",
    "            class_directory = os.path.join(data_directory, class_name)\n",
    "            if os.path.isdir(class_directory):\n",
    "                all_data.setdefault(class_name, []).extend(os.path.join(class_directory, file_name) for file_name in os.listdir(class_directory))\n",
    "\n",
    "    for class_name, files in all_data.items():\n",
    "        print(f\"Class '{class_name}' has {len(files)} images\")\n",
    "\n",
    "    dataset_splits = {'training': [], 'validation': [], 'testing': []}\n",
    "\n",
    "    for class_name, files in all_data.items():\n",
    "        training_dataset, temporary_dataset = train_test_split(files, test_size=(1 - split_ratios[0]), random_state=42)\n",
    "\n",
    "        validation_dataset, testing_dataset = train_test_split(temporary_dataset, test_size=split_ratios[2]/(split_ratios[1] + split_ratios[2]), random_state=42)\n",
    "\n",
    "        dataset_splits['training'].extend(training_dataset)\n",
    "        dataset_splits['validation'].extend(validation_dataset)\n",
    "        dataset_splits['testing'].extend(testing_dataset)\n",
    "\n",
    "    return dataset_splits\n",
    "\n",
    "dataset_directories = [lung_dataset, colon_dataset]\n",
    "dataset_splits = prepare_splits(dataset_directories)\n",
    "\n",
    "print(f\"Training dataset has {len(dataset_splits['training'])} images\")\n",
    "print(f\"Validation dataset has {len(dataset_splits['validation'])} images\")\n",
    "print(f\"Testing dataset has {len(dataset_splits['testing'])} images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Class\n",
    "Initializes the dataset class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CancerDetectionDataset(Dataset):\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
